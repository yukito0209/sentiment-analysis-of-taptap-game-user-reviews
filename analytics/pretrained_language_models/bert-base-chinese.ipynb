{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a8576c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d6131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67307505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(r\"D:\\GitHubRepos\\is6941-ml-social-media\\taptap\\data\\integrated\\lm_cleaned_taptap_reviews.csv\")\n",
    "df = df[['review_content', 'sentiment']].dropna()\n",
    "df['sentiment'] = df['sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3bb53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['review_content'].tolist(),\n",
    "    df['sentiment'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac56dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated dataset class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.encodings = tokenizer(texts, \n",
    "                                 padding='max_length',  # Uniform padding length\n",
    "                                 truncation=True, \n",
    "                                 max_length=256)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a80e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = torch.tensor(\n",
    "    [len(train_labels)/sum(train_labels),  # Positive class weight\n",
    "     len(train_labels)/(len(train_labels)-sum(train_labels))],  # Negative class weight\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f697f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "# Modify model initialization\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-chinese\",\n",
    "    num_labels=2,\n",
    "    # problem_type=\"single_label_classification\",\n",
    "    # hidden_dropout_prob=0.3,\n",
    "    # classifier_dropout=0.2\n",
    ")\n",
    "\n",
    "# Move class weights to GPU\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets (keep CPU tensors)\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (automatically handle data to GPU)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    fp16=True,  # Automatically enable pin_memory\n",
    "    dataloader_pin_memory=True,  # Explicitly enable memory pinning\n",
    "    # learning_rate=3e-5,  # Lower initial learning rate from default 5e-5\n",
    "    # warmup_ratio=0.1,    # Add learning rate warmup\n",
    "    # weight_decay=0.01,   # L2 regularization\n",
    "    # gradient_accumulation_steps=2,   # Gradient accumulation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e732d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluation function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(labels, preds))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(labels, preds))\n",
    "    return {'accuracy': (preds == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07146ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f835f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 07:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.365370</td>\n",
       "      <td>0.834188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.380965</td>\n",
       "      <td>0.836939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.472908</td>\n",
       "      <td>0.839815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      2740\n",
      "           1       0.88      0.86      0.87      5257\n",
      "\n",
      "    accuracy                           0.83      7997\n",
      "   macro avg       0.81      0.82      0.82      7997\n",
      "weighted avg       0.84      0.83      0.84      7997\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2140  600]\n",
      " [ 726 4531]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.74      2740\n",
      "           1       0.85      0.91      0.88      5257\n",
      "\n",
      "    accuracy                           0.84      7997\n",
      "   macro avg       0.83      0.80      0.81      7997\n",
      "weighted avg       0.83      0.84      0.83      7997\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1883  857]\n",
      " [ 447 4810]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      2740\n",
      "           1       0.87      0.89      0.88      5257\n",
      "\n",
      "    accuracy                           0.84      7997\n",
      "   macro avg       0.82      0.82      0.82      7997\n",
      "weighted avg       0.84      0.84      0.84      7997\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2037  703]\n",
      " [ 578 4679]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.30004727681477866, metrics={'train_runtime': 466.4451, 'train_samples_per_second': 205.735, 'train_steps_per_second': 6.432, 'total_flos': 1.262459465828352e+16, 'train_loss': 0.30004727681477866, 'epoch': 3.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training (automatically handle data migration)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641def6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      2740\n",
      "           1       0.87      0.89      0.88      5257\n",
      "\n",
      "    accuracy                           0.84      7997\n",
      "   macro avg       0.82      0.82      0.82      7997\n",
      "weighted avg       0.84      0.84      0.84      7997\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2037  703]\n",
      " [ 578 4679]]\n",
      "\n",
      "Final Test Set Evaluation:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      2740\n",
      "           1       0.87      0.89      0.88      5257\n",
      "\n",
      "    accuracy                           0.84      7997\n",
      "   macro avg       0.82      0.82      0.82      7997\n",
      "weighted avg       0.84      0.84      0.84      7997\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2037  703]\n",
      " [ 578 4679]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8398149305989746}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final test set evaluation\n",
    "test_results = trainer.predict(test_dataset)\n",
    "print(\"\\nFinal Test Set Evaluation:\")\n",
    "compute_metrics(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "保存测试集预测概率 (BERT)...\n",
      "BERT 概率已保存到 predictions/probabilities_bert.npy\n"
     ]
    }
   ],
   "source": [
    "# --- Save Probabilities for Ensemble ---\n",
    "print(\"\\nSaving test set prediction probabilities (BERT)...\")\n",
    "# Trainer.predict returns logits in test_results.predictions\n",
    "# Apply Softmax to get probabilities\n",
    "logits = torch.tensor(test_results.predictions)\n",
    "probabilities = torch.softmax(logits, dim=-1).numpy() # Convert to numpy array\n",
    "np.save(r'D:\\GitHubRepos\\is6941-ml-social-media\\taptap\\analytics\\predictions\\probabilities_bert.npy', probabilities)\n",
    "print(\"BERT probabilities saved to predictions/probabilities_bert.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS6941",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
